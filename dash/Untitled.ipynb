{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Importar librer√≠as\n",
    "from __future__ import print_function\n",
    "import json\n",
    "import time\n",
    "import datetime as datetime\n",
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#en caso de utlizar python2 en lugar de python3\n",
    "try:\n",
    "    from urllib.request import urlopen\n",
    "except ImportError:\n",
    "    from urllib2 import urlopen\n",
    "\n",
    "#maximo de intentos en caso de falla del internet\n",
    "MAX_ATTEMPTS = 6\n",
    "\n",
    "#Llamando al servicio de Iowa State University\n",
    "SERVICE = \"http://mesonet.agron.iastate.edu/cgi-bin/request/asos.py?\"\n",
    "#La fecha iniciar es el dia de hoy a las 00:00\n",
    "start=datetime.datetime.now()\n",
    "#La fecha final es manana a las 00:00\n",
    "\n",
    "end=start + timedelta(days=1)\n",
    "#startts = datetime.datetime(start.year,start.month,start.day)\n",
    "#endts = datetime.datetime(end.year,end.month,end.day)\n",
    "startts = datetime.datetime(2019,11,1)\n",
    "endts = datetime.datetime(2019,11,17)\n",
    "\n",
    "##################################\n",
    "#funcion para descargar la data\n",
    "def download_data(uri):\n",
    "    attempt = 0\n",
    "    while attempt < MAX_ATTEMPTS:\n",
    "        try:\n",
    "            data = urlopen(uri, timeout=300).read().decode(\"utf-8\")\n",
    "            if data is not None and not data.startswith(\"ERROR\"):\n",
    "                return data\n",
    "        except Exception as exp:\n",
    "            print(\"download_data(%s) failed with %s\" % (uri, exp))\n",
    "            time.sleep(5)\n",
    "        attempt += 1\n",
    "    print(\"Exhausted attempts to download, returning empty data\")\n",
    "    return \"\"\n",
    "####################################\n",
    "\n",
    "#creacion de los parametros para el API\n",
    "service = SERVICE + \"data=all&tz=Etc/UTC&format=comma&latlon=no&\"\n",
    "service += startts.strftime(\"year1=%Y&month1=%m&day1=%d&\")\n",
    "service += endts.strftime(\"year2=%Y&month2=%m&day2=%d&\")\n",
    "#definicion de network y estaciones de donde descargaremos\n",
    "networks = [\"CO__ASOS\"]\n",
    "#stations=[\"SKAR\",\"SKQL\",\"SKBO\",\"SKBG\",\"SKCL\",\"SKCC\",\"SKCG\",\"SKPE\",\"SKSP\",\"SKSM\",\"SKMR\"]\n",
    "stations=[\"SKAR\"]\n",
    "\n",
    "#iniciar la descarga por cada estacion\n",
    "df = pd.DataFrame()\n",
    "for station in stations:\n",
    "    uri = \"%s&station=%s\" % (service, station)\n",
    "    print(\"Downloading: %s\" % (station,))\n",
    "    data = download_data(uri)\n",
    "    data = pd.DataFrame([x.split(',') for x in data.split('\\n')]).iloc[5:].reset_index(drop=True)\n",
    "    data.columns = data.iloc[0]\n",
    "    data = data.drop(data.index[0])\n",
    "    df = df.append(data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eliminacion de campos no usados\n",
    "del df['metar']\n",
    "del df['wxcodes']\n",
    "del df['lon']\n",
    "del df['lat']\n",
    "del df['skyc2']\n",
    "del df['skyc3']\n",
    "del df['skyc4']\n",
    "del df['skyl2']\n",
    "del df['skyl3']\n",
    "del df['skyl4']\n",
    "del df['ice_accretion_1hr']\n",
    "del df['ice_accretion_3hr']\n",
    "del df['ice_accretion_5hr']\n",
    "del df['peak_wind_gust']\n",
    "del df['peak_wind_drct']\n",
    "del df['peak_wind_time']\n",
    "print(df.shape)\n",
    "\n",
    "#creacion del motor de base de datos en postgres\n",
    "engine = create_engine('postgresql://ds4a_18:ds4a2019@ds4a18.cmlpaj0d1yqv.us-east-2.rds.amazonaws.com:5432/Airports_ds4a')\n",
    "#subir DataFrame a la base de datos\n",
    "df.to_sql(name='DataRaw', con=engine, if_exists = 'append', index=False, chunksize=10000)\n",
    "#eliminacion de duplicados con el query. Esta como una funcion en la base de datos\n",
    "engine.execute('select delete_duplicates()')\n",
    "#eliminacion de datos nulos (donde VALID es nulo)\n",
    "engine.execute('delete from DataRaw where valid is null')\n",
    "print('FINISH')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
